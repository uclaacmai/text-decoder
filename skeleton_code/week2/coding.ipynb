{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some potentially useful imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look at the data\n",
    "data_path = Path(\"../../dad_jokes.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so our data is a little messy, lets fix it\n",
    "\n",
    "\"\"\" ToDo:\n",
    "- rename the second column named \"Data Jokes\" to \"text\"\n",
    "- first remove the first column named \"#\" \n",
    "Here is some useful documentation:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "\"\"\"\n",
    "data_path = Path(\"../../dad_jokes.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "#### Your Code ####\n",
    "\n",
    "\n",
    "###################\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like this: \n",
    "\n",
    "| |text|\n",
    "|--|----|\n",
    "|0\t|A steak pun is a rare medium well done.|\n",
    "|1\t|They say that breakfast is the most important ...|\n",
    "|2\t|What do you get if you cross an angry sheep wi...|\n",
    "|3\t|An apple a day keeps the doctor away. At least...|\n",
    "|4\t|What sounds like a sneeze and is made of leath...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to find the conditional probability of each token given that we know the previous token\n",
    "# practically to do this we need to know the number of times token 1 was followed by token 2\n",
    "# if the sequence ends there is no subsequent token, in which case we insert a special token,\n",
    "# which is called end_token here, that denotes the sequence has ended\n",
    "\"\"\" ToDo:\n",
    "- Here we have split_text which holds a list of strings (tokens) \n",
    "- vocabulary is a dictionary which maps each token to a dictionary of tokens to frequency\n",
    "- use conditionals to check if the current word is already in the dictionary\n",
    "- and if so check if the next token is in the dictionary the word maps to and increment it\n",
    "- if not make it map to a dictionary with the next token mapping to 1\n",
    "\n",
    "note:\n",
    "Make sure that all words are lower case and have no whitespace\n",
    "You may also find that in some datasets there is an empty string word ignore it\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_next_token_frequency(\n",
    "    df: pd.DataFrame, end_token=\"<eos>\"\n",
    ") -> dict[str : dict[str:int]]:\n",
    "    vocabulary = {}\n",
    "    for index, row in df.iterrows():\n",
    "        split_text = re.findall(r'\\w+|[.,!?;\":]', row[\"text\"])\n",
    "        for index in range(len(split_text)):\n",
    "            word = split_text[index].strip().lower()  # noqa\n",
    "\n",
    "            #### Your Code ####\n",
    "\n",
    "            ###################\n",
    "\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    \"hi, I like deep learning\",\n",
    "    \"I actually prefer classical machine learning.\",\n",
    "    \"meh, I like classical machines\",\n",
    "]\n",
    "get_next_token_frequency(pd.DataFrame(sample, columns=[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test should return\n",
    "\n",
    "{'hi': {',': 1}, \\\n",
    " ',': {'i': 2}, \\\n",
    " 'i': {'like': 2, 'actually': 1}, \\\n",
    " 'like': {'deep': 1, 'classical': 1}, \\\n",
    " 'deep': {'learning': 1}, \\\n",
    " 'learning': {'<eos>': 1, '.': 1}, \\\n",
    " 'actually': {'prefer': 1}, \\\n",
    " 'prefer': {'classical': 1}, \\\n",
    " 'classical': {'machine': 1, 'machines': 1},\\\n",
    " 'machine': {'learning': 1}, \\\n",
    " '.': {'<eos>': 1}, \\\n",
    " 'meh': {',': 1}, \\\n",
    " 'machines': {'<eos>': 1}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the frequency with which each token follows the other tokens\n",
    "# we need to calculate the *probability* each token follows each other token\n",
    "# this is easiest to implment as a dictionary that maps each token to\n",
    "# a list of tuples in decending order of frequency where the first element represents\n",
    "# the cummulative probablity of that token and the second is the token's value\n",
    "\"\"\" ToDo:\n",
    "- Iterate through the items in vocabulary and calculate the total of all the frequencies in the dictionaries\n",
    "- Then calculate the probability that frequency has, sort this is ascending order,\n",
    "- then use it to calculate the cummulative probability, which the probability_dictonary will map\n",
    "- each token to\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def convert_frequency_to_probability(\n",
    "    vocabulary: dict[str : dict[str:int]],\n",
    ") -> dict[str : list[tuple[float, str]]]:\n",
    "    probability_dictonary = {}\n",
    "\n",
    "    #### Your Code ####\n",
    "\n",
    "    ###################\n",
    "\n",
    "    return probability_dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    \"hi, I like deep learning\",\n",
    "    \"I actually prefer classical machine learning.\",\n",
    "    \"meh, I like classical machines\",\n",
    "]\n",
    "vocabulary = get_next_token_frequency(pd.DataFrame(sample, columns=[\"text\"]))\n",
    "convert_frequency_to_probability(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test code should return:\n",
    "\n",
    "{'hi': [(1.0, ',')], \\\n",
    " ',': [(1.0, 'i')], \\\n",
    " 'i': [(0.6666666666666666, 'like'), (1.0, 'actually')], \\\n",
    " 'like': [(0.5, 'deep'), (1.0, 'classical')], \\\n",
    " 'deep': [(1.0, 'learning')], \\\n",
    " 'learning': [(0.5, '<eos>'), (1.0, '.')], \\\n",
    " 'actually': [(1.0, 'prefer')], \\\n",
    " 'prefer': [(1.0, 'classical')], \\\n",
    " 'classical': [(0.5, 'machine'), (1.0, 'machines')], \\\n",
    " 'machine': [(1.0, 'learning')], \\\n",
    " '.': [(1.0, '<eos>')], \\\n",
    " 'meh': [(1.0, ',')], \\\n",
    " 'machines': [(1.0, '<eos>')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now assemble a class that we can use to generate our sentences\n",
    "class StateMachine:\n",
    "    # note that these static variables denote that we will be storing some variable of\n",
    "    # the below names and types in self\n",
    "    state_probabilities: dict[str : list[tuple[float, str]]]\n",
    "    end_token: str\n",
    "\n",
    "    def __init__(self, csv_path: str, end_token=\"<eos>\") -> None:\n",
    "        \"\"\"ToDo:\n",
    "        - Use pandas to read in the csv and then use get_next_token_frequency and\n",
    "        - convert_frequency_to_probability to get the probabilities of the next state\n",
    "        - and store that in state_probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        #### Your Code ####\n",
    "\n",
    "        ###################\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_next_token(self, current_token: str) -> str:\n",
    "        \"\"\"ToDo:\n",
    "        - Given the current_token find the probabilities of the subsuquent tokens in state_probabilities\n",
    "        - get a random number between 0 and 1 using random.uniform(0, 1) and find the first\n",
    "        - iterate through the probabilities and find the first probability that is <= the random number\n",
    "        \"\"\"\n",
    "\n",
    "        #### Your Code ####\n",
    "\n",
    "        ###################\n",
    "\n",
    "        pass\n",
    "\n",
    "    def generate_sequence(self, starting_token: str) -> list[str]:\n",
    "        \"\"\"ToDo:\n",
    "        - while the last token in the sequence is not the end_token (<eos> by default)\n",
    "        - pass the last token in ouput to get_next_token and append the result to output\n",
    "        \"\"\"\n",
    "        output = [starting_token.lower()]\n",
    "\n",
    "        #### Your Code ####\n",
    "\n",
    "        ###################\n",
    "\n",
    "        return self.correct_punctuation_and_spacing(\" \".join(output[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_markov_chain = StateMachine(Path(\"../../dad_jokes.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(my_markov_chain.get_next_token(\"2019\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test should give some combination of \",\" and \"afraid\"\n",
    "\\\n",
    "I got: \\\n",
    ", \\\n",
    ", \\\n",
    "afraid \\\n",
    ", \\\n",
    "afraid \\\n",
    ", \\\n",
    "afraid \\\n",
    ", \\\n",
    "afraid \\\n",
    ", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_markov_chain.generate_sequence(\"I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is our final product put together, some of the dad jokes it generated for me were: \\\n",
    "'I gave birth.' \\\n",
    "'I don t work out of cheese. \" \" my class dairy! That blue ship for being selfless, thank god took too long have you heard buzzing, as he had a stick a seafood diet!' \\\n",
    "'I made of boundaries. I can february march? 3k.' \\\n",
    "'I m finally knocks again! !' \\\n",
    "'I ve only fans.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
